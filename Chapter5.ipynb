{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdIeN6WMr9Ldkg7wjGPpjn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yu0ki/BERT_Practice/blob/main/Chapter5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su1ehFmQ5i8u",
        "outputId": "f2cf4bd7-5903-4862-999b-a941cea68b92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.5.0 in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: fugashi==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: ipadic==1.0.0 in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2022.6.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (0.0.53)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.12.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.0) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# この章では、BERTを使って穴埋めタスクを行う\n",
        "\n",
        "\n",
        "# ライブラリたち\n",
        "!pip install transformers==4.5.0 fugashi==1.1.0 ipadic==1.0.0\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertJapaneseTokenizer, BertForMaskedLM\n",
        "\n",
        "\n",
        "# ちなみに、BertForMaskedLMは特殊トークン[MASK]に入るトークンを語彙の中から予測するクラス"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# まずはトークナイザを準備\n",
        "\n",
        "model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "# 次は穴埋めタスク用の事前学習済みモデルを準備\n",
        "bert_mlm = BertForMaskedLM.from_pretrained(model_name)\n",
        "# GPUにのっける\n",
        "bert_mlm = bert_mlm.cuda()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "p5wVH3v06fet",
        "outputId": "988e031f-2376-4068-ad50-547033508c0b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-eb57c62ab78a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cl-tohoku/bert-base-japanese-whole-word-masking'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertJapaneseTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BertJapaneseTokenizer' object has no attribute 'cuda'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 「今日は[MASK]へ行く。」　を穴埋めしてみよう\n",
        "\n",
        "# ・・・とその前に、まずは文章をトークン化したものを見てみよう（[MASK]がちゃんとトークンと見做されている）\n",
        "text = \"今日は[MASK]へ行く。\"\n",
        "tokens = tokenizer.tokenize(text)\n",
        "print(tokens)\n",
        "\n",
        "\n",
        "# 手順1：トークン列をトークンIDで置き換える(符号化)\n",
        "input_ids = tokenizer.encode(text, return_tensors = 'pt')\n",
        "print(input_ids)\n",
        "\n",
        "# そしてGPUへ送り込む\n",
        "input_ids = input_ids.cuda()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUfBo1nJ85If",
        "outputId": "7a9f4e45-d05b-4311-b4cd-1be7913d813d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['今日', 'は', '[MASK]', 'へ', '行く', '。']\n",
            "tensor([[   2, 3246,    9,    4,  118, 3488,    8,    3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 手順２：BERTに入力して分類スコアを得る\n",
        "# １文しか入力してないので、input_ids以外の指定（トークンの最大数とか）が必要ない\n",
        "with torch.no_grad():\n",
        "  output = bert_mlm(input_ids = input_ids)\n",
        "# print(output)\n",
        "\n",
        "# outputの属性のうち「logits」が、語彙中の各単語に対する分類スコアである\n",
        "# scoresは、三次元配列：各次元数（サイズ）は(バッチサイズ, 系列長, 語彙のサイズ)\n",
        "# scores[i, j, k] = 入力された文章のi文目に対応するトークン列の、j番目のトークンに対して、トークンIDがkの語彙のスコア\n",
        "scores = output.logits\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvVHfnLU-ajj",
        "outputId": "afe9ea2f-8461-443d-8674-13b77c0c9ce6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ -5.8525,   5.0457,  -1.7965,  ...,  -4.8386,  -6.4219,  -7.8085],\n",
            "         [ -4.0218,   7.2845,  -5.3993,  ...,  -6.0369,  -6.5811,  -2.1289],\n",
            "         [ -5.8364,   5.3641,  -2.2106,  ...,  -4.3529,  -5.7284,  -4.3889],\n",
            "         ...,\n",
            "         [ -7.8698,   5.9753,  -4.3922,  ...,  -4.3223,  -6.0900, -11.4386],\n",
            "         [ -5.4500,   6.5491,   0.0368,  ...,  -4.5615,  -5.1636,  -7.0161],\n",
            "         [ -8.7510,   3.2686,  -1.6596,  ...,  -5.0593,  -7.0547, -10.7624]]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ちなみにBertForMaskedMLは\n",
        "# 入力 -> BertModelに入力を入れた時の出力 -> それを線形変換 -> GELU関数（活性化関数） -> 線形変換 -> 最終出力"
      ],
      "metadata": {
        "id": "4nakb6nLBGSS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 手順３：scoresから[MASK]に入るトークンを予測\n",
        "\n",
        "# まず、入力された文章（or　文章集合）から、[MASK]（こいつのトークンIDは4）の位置（配列のインデックス）を求める\n",
        "# input_ids[i].tolist().index(4) : i文目の中でID4に対応するインデックス\n",
        "mask_position = input_ids[0].tolist().index(4)\n",
        "\n",
        "# スコアが最も良いトークンのIDを取り出す\n",
        "# argmax：配列で、一番大きい要素の「インデックス（順番）」を返す関数。括弧の中は初期値（省略可能）\n",
        "id_best = scores[0, mask_position].argmax(-1).item()\n",
        "\n",
        "# id_bestに対応するトークンを入手\n",
        "token_best = tokenizer.convert_ids_to_tokens(id_best)\n",
        "\n",
        "# 取り出したトークンに「##」がついていた場合(Chapter4参照)は、それを取り除く\n",
        "token_best = token_best.replace(\"##\", \"\")\n",
        "\n",
        "# 元の入力文章の{MASK}を、token_bestで置き換える\n",
        "final_text = text.replace(\"[MASK]\", token_best)\n",
        "print(final_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-bOxb3qEF6R",
        "outputId": "e537b72d-c710-4e97-e89d-532191bf1a51"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "今日は東京へ行く。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 最上位１位だけでなく、上位１０位を求めてみよう\n",
        "\n",
        "# まずは、text, tokenizer, bert_mlm, num_topk(=上位k件)を入力として、上位num_topk件の穴埋め予測を出す関数を定義\n",
        "def predict_mask_topk(text, tokenizer, bert_mlm, num_topk):\n",
        "\n",
        "  # テキストを符号化\n",
        "  input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "  input_ids = input_ids.cuda()\n",
        "\n",
        "\n",
        "\n",
        "  # bert_mlmに入力（計算結果を保存しないことで、リソースを節約）\n",
        "  with torch.no_grad():\n",
        "    output = bert_mlm(input_ids = input_ids)\n",
        "  # 分類スコアを取得\n",
        "  scores = output.logits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # トークンID ４　に対応する、input_idsのインデックスを求める\n",
        "  mask_position = input_ids[0].tolist().index(4)\n",
        "\n",
        "  # scoresから上位num_topk件を取得\n",
        "  # topk(n) は上位n件を取得してくれる\n",
        "  scores_topk = scores[0, mask_position].topk(num_topk)\n",
        "\n",
        "  # scores_topkのスコアを持つトークンのID列\n",
        "  # indices はnumpy が提供する関数っぽい。\n",
        "  # scores_topkのscores[0, masked_position]内でのindex (=token id)を取得\n",
        "  ids_topk = scores_topk.indices\n",
        "\n",
        "  # ids_topkを対応するトークンへ変換\n",
        "  tokens_topk = tokenizer.convert_ids_to_tokens(ids_topk)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 以上で求めた上位トークンで文中の[MASK]を置き換える\n",
        "  text_topk = []\n",
        "  for token in tokens_topk:\n",
        "    token = token.replace('##', '')\n",
        "    text_topk.append(text.replace('[MASK]', token))\n",
        "\n",
        "  return text_topk\n",
        "\n"
      ],
      "metadata": {
        "id": "fuGtT2MyJGI2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 上記の関数で、上位１０件の文章を出力してみよう\n",
        "\n",
        "text_topk = predict_mask_topk (text, tokenizer, bert_mlm, 10)\n",
        "\n",
        "# * : 配列を展開\n",
        "#  sep : 区切り方指定\n",
        "# option + ¥ でバックスラッシュを打てる\n",
        "print(*text_topk, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K1W7t8iRm-g",
        "outputId": "39436803-69cd-45e2-c20b-d5559ea715d4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "今日は東京へ行く。\n",
            "今日はハワイへ行く。\n",
            "今日は学校へ行く。\n",
            "今日はニューヨークへ行く。\n",
            "今日はどこへ行く。\n",
            "今日は空港へ行く。\n",
            "今日はアメリカへ行く。\n",
            "今日は病院へ行く。\n",
            "今日はそこへ行く。\n",
            "今日はロンドンへ行く。\n"
          ]
        }
      ]
    }
  ]
}